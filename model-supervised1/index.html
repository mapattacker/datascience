
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.6">
    
    
      
        <title>Classification - Data Science in Python</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6910b76c.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.196e0c26.min.css">
        
          
          
          <meta name="theme-color" content="#2094f3">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="blue" data-md-color-accent="">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#classification" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href=".." title="Data Science in Python" class="md-header-nav__button md-logo" aria-label="Data Science in Python">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Data Science in Python
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Classification
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/mapattacker/datascience/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mapattacker/datascience
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Data Science in Python" class="md-nav__button md-logo" aria-label="Data Science in Python">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Data Science in Python
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/mapattacker/datascience/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mapattacker/datascience
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." class="md-nav__link">
      Introduction
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../process/" class="md-nav__link">
      ML Process
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../datasets/" class="md-nav__link">
      Datasets
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../data-exploration/" class="md-nav__link">
      Data Exploration
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5" >
    <label class="md-nav__link" for="nav-5">
      Data Preparation
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Data Preparation" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon"></span>
        Data Preparation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../data-preprocessing/" class="md-nav__link">
      Feature Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../data-scaling/" class="md-nav__link">
      Feature Scaling
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../data-engineering/" class="md-nav__link">
      Feature Engineering
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../data-classimbalance/" class="md-nav__link">
      Class Imbalance
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../model-concepts/" class="md-nav__link">
      Model Concepts
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7" checked>
    <label class="md-nav__link" for="nav-7">
      Model Supervised
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Model Supervised" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        <span class="md-nav__icon md-icon"></span>
        Model Supervised
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Classification
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" class="md-nav__link md-nav__link--active">
      Classification
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    KNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    Naive Bayes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machines" class="md-nav__link">
    Support Vector Machines
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    Logistic Regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-ensembles" class="md-nav__link">
    Tree Ensembles
  </a>
  
    <nav class="md-nav" aria-label="Tree Ensembles">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    Random Forest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    Gradient Boosting
  </a>
  
    <nav class="md-nav" aria-label="Gradient Boosting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    XGBoost
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    LightGBM
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#catboost" class="md-nav__link">
    CatBoost
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voting" class="md-nav__link">
    Voting
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stacking" class="md-nav__link">
    Stacking
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-supervised2/" class="md-nav__link">
      Regression
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8" >
    <label class="md-nav__link" for="nav-8">
      Model Unsupervised
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Model Unsupervised" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        <span class="md-nav__icon md-icon"></span>
        Model Unsupervised
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../model-unsupervised1/" class="md-nav__link">
      Transformation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-unsupervised2/" class="md-nav__link">
      Clustering
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-unsupervised3/" class="md-nav__link">
      One-Class
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-unsupervised4/" class="md-nav__link">
      Distance
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-unsupervised5/" class="md-nav__link">
      Association
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9" >
    <label class="md-nav__link" for="nav-9">
      Model Selection
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Model Selection" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        <span class="md-nav__icon md-icon"></span>
        Model Selection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../model-crossvalidation/" class="md-nav__link">
      Cross Validation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-tuning/" class="md-nav__link">
      Model Tuning
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-evaluation/" class="md-nav__link">
      Model Evaluation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../model-explainability/" class="md-nav__link">
      Model Explainability
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../persistence/" class="md-nav__link">
      Model Persistence
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#knn" class="md-nav__link">
    KNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    Naive Bayes
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#support-vector-machines" class="md-nav__link">
    Support Vector Machines
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    Logistic Regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tree-ensembles" class="md-nav__link">
    Tree Ensembles
  </a>
  
    <nav class="md-nav" aria-label="Tree Ensembles">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    Random Forest
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting" class="md-nav__link">
    Gradient Boosting
  </a>
  
    <nav class="md-nav" aria-label="Gradient Boosting">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#xgboost" class="md-nav__link">
    XGBoost
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lightgbm" class="md-nav__link">
    LightGBM
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#catboost" class="md-nav__link">
    CatBoost
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#voting" class="md-nav__link">
    Voting
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stacking" class="md-nav__link">
    Stacking
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/mapattacker/datascience/edit/master/docs/model-supervised1.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="classification">Classification</h1>
<p>Supervised classification is done when the label is a categorical variable.</p>
<h2 id="knn">KNN</h2>
<p><a href="https://scikit-learn.org/stable/modules/neighbors.html#classification">K-Nearest Neighbours</a> is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point.</p>
<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/knn.gif?raw=true" style="width:100%" />
  <figcaption>A majority vote of k (www.mathworks.com)</figcaption>
</figure>

<table>
<thead>
<tr>
<th>Hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>n_neighbors</td>
<td>no. nearest neighbours from a point to assign a class. default 5</td>
</tr>
<tr>
<td>metric</td>
<td>default=’minkowski’, i.e. euclidean</td>
</tr>
</tbody>
</table>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="c1"># 0.53333333333333333</span>
</code></pre></div>


<hr>

<h2 id="naive-bayes">Naive Bayes</h2>
<p><a href="https://scikit-learn.org/stable/modules/naive_bayes.html">Naive Bayes</a> is a probabilistic model using the Bayes' theorem. Features are assumed to be independent of each other in a given class (hence naive). This makes the math very easy. E.g., words that are unrelated multiply together to form the final probability.</p>
<p>There are 5 variants of Naive Bayes in <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes">sklearn</a>. Bernouli and Multinomial models are commonly used for sparse count data like text classification. The latter normally works better. Gaussian model is used for high-dimensional data.</p>
<table>
<thead>
<tr>
<th>Hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>alpha</td>
<td>smoothing (generalisation) parameter (default 1.0)</td>
</tr>
</tbody>
</table>
<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/naivebayes.png?raw=true" style="width:80%" />
  <figcaption>University of Michigan: Coursera Data Science in Python</figcaption>
</figure>

<hr>

<h2 id="support-vector-machines">Support Vector Machines</h2>
<p><a href="https://scikit-learn.org/stable/modules/svm.html">Support Vector Machines</a> (SVM) involves locating the support vectors of two boundaries to find a maximum tolerance hyperplane.</p>
<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/svm.png?raw=true" style="width:70%" />
  <figcaption>University of Michigan: Coursera Data Science in Python</figcaption>
</figure>

<table>
<thead>
<tr>
<th>Key hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>C</td>
<td>lower C more L2 regularization</td>
</tr>
<tr>
<td>kernel</td>
<td>linear or radial basis function (rbf)</td>
</tr>
<tr>
<td>gamma</td>
<td>from v0.22, gamma is auto or scaled, rather than a float</td>
</tr>
</tbody>
</table>
<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/svm_parameters.PNG?raw=true" style="width:100%" />
  <figcaption></figcaption>
</figure>

<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>


<p>If we require linear SVM, we should use <code>LinearSVC</code> with its flexibility of regularization and loss functions, together with faster compute time for large datasets.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;squared_hinge&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>


<hr>

<h2 id="logistic-regression">Logistic Regression</h2>
<p>While it is a type of regression, it only outputs a binary value hence it is considered a classification model.</p>
<table>
<thead>
<tr>
<th>Key hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>penalty</td>
<td>l1/l2/elasticnet</td>
</tr>
<tr>
<td>C</td>
<td>lower C more regularization</td>
</tr>
</tbody>
</table>
<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/logisticR.png?raw=true" style="width:80%" />
  <figcaption></figcaption>
</figure>

<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">acc_train</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">acc_test</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>


<hr>

<h2 id="decision-tree">Decision Tree</h2>
<p>Uses gini index (default) or entropy to split the data at binary level.</p>
<p>Strengths: Can select a large number of features that best determine the targets.</p>
<p>Weakness: Tends to overfit the data as it will split till the end. Pruning (using max_depth &amp; min_samples_leaf) can be done to remove the leaves to prevent overfitting. Small changes in data can lead to different splits. Not very reproducible for future data (tree ensemble methods are better).</p>
<table>
<thead>
<tr>
<th>Key hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>max_depth</td>
<td>The maximum depth of the tree</td>
</tr>
<tr>
<td>min_samples_leaf</td>
<td>The minimum number of samples required before splitting</td>
</tr>
</tbody>
</table>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
<span class="n">train_test_split</span><span class="p">(</span><span class="n">predictor</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_features</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
<span class="c1"># 0.973684210526</span>

<span class="c1"># Feature importance</span>
<span class="n">f_impt</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">f_impt</span> <span class="o">=</span> <span class="n">f_impt</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">f_impt</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature importance&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f_impt</span><span class="p">)</span>
<span class="c1"># petal width (cm)      0.952542</span>
<span class="c1"># petal length (cm)     0.029591</span>
<span class="c1"># sepal length (cm)     0.017867</span>
<span class="c1"># sepal width (cm)      0.000000</span>
</code></pre></div>


<p>Viewing the decision tree requires installing of the two packages conda install graphviz &amp; conda install pydotplus.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.externals.six</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>

<span class="n">dot_data</span> <span class="o">=</span> <span class="n">StringIO</span><span class="p">()</span>
<span class="n">export_graphviz</span><span class="p">(</span><span class="n">dtree</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="n">dot_data</span><span class="p">,</span>
                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">rounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">special_characters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="o">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span>
<span class="n">Image</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">create_png</span><span class="p">())</span>
</code></pre></div>


<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/decisiongraph.png?raw=true" style="width:90%" />
  <figcaption></figcaption>
</figure>

<hr>

<h2 id="tree-ensembles">Tree Ensembles</h2>
<h3 id="random-forest">Random Forest</h3>
<p>An ensemble of decision trees. Used to be one of the most popular tree classifiers. But now generally superceded by other variants like XGBoost, LightGBM etc.</p>
<p>Each decision tree is random, introduced through <strong>bootstrap</strong> (aka, bagging), i.e. sample of size N is created by just repeatedly picking one of the N dataset rows at random with replacement, as well as <strong>random feature splits</strong>, i.e., when picking the best split for a node, instead of finding the best split across all possible features (decision tree), a random subset of features is chosen and the best split is found within that smaller subset of features</p>
<p>As a result of this randomness, the model is very generalized.</p>
<table>
<thead>
<tr>
<th>Key hyperparameter(s)</th>
<th>Desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>n_estimators</td>
<td>no. decision trees</td>
</tr>
<tr>
<td>max_features</td>
<td>max random features to split a leaf node</td>
</tr>
</tbody>
</table>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span>

<span class="n">train_feature</span><span class="p">,</span> <span class="n">test_feature</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">test_target</span> <span class="o">=</span> \
<span class="n">train_test_split</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>


<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_feature</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_feature</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
<span class="mf">0.823529411765</span>

<span class="c1"># feature importance</span>
<span class="n">f_impt</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">f_impt</span> <span class="o">=</span> <span class="n">f_impt</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">f_impt</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feature importance&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f_impt</span><span class="p">)</span>
</code></pre></div>


<p>To see how many decision trees are minimally required make the accuracy plateau.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">trees</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">accuracy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trees</span><span class="p">)):</span>
  <span class="n">clf</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">model</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_feature</span><span class="p">,</span> <span class="n">train_target</span><span class="p">)</span>
  <span class="n">predictions</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_feature</span><span class="p">)</span>
  <span class="n">accuracy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_target</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trees</span><span class="p">,</span><span class="n">accuracy</span><span class="p">)</span>
</code></pre></div>


<figure>
  <img src="https://github.com/mapattacker/datascience/blob/master/images/randomforest.png?raw=true" style="width:90%" />
  <figcaption>Accuracy over no. trees trained with</figcaption>
</figure>

<h3 id="gradient-boosting">Gradient Boosting</h3>
<p>The general idea of most boosting methods is to train predictors sequentially, each trying to correct its predecessor. Gradient boosting tries to fit the new predictor to the residual errors made by the previous predictor.</p>
<p>Built in a non-random way, to create a model that makes fewer and fewer mistakes as more trees are added. Once the model is built, making predictions with a gradient boosted tree models is fast and doesn’t use a lot of memory.</p>
<h4 id="xgboost">XGBoost</h4>
<p><a href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a> or eXtreme Gradient Boosting, is a form of gradient boosted decision trees is that designed to be highly efficient, flexible and portable.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">y_pred</span><span class="p">]</span>

<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
</code></pre></div>


<h4 id="lightgbm">LightGBM</h4>
<p><a href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a> (Light Gradient Boosting) is a lightweight version of gradient boosting developed by Microsoft. It has similar performance to XGBoost but touted to run much faster than it.</p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">lightgbm</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
<span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Create the LightGBM data containers</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lightgbm</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">lightgbm</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;application&#39;</span><span class="p">:</span> <span class="s1">&#39;binary&#39;</span><span class="p">,</span>
  <span class="s1">&#39;objective&#39;</span><span class="p">:</span> <span class="s1">&#39;binary&#39;</span><span class="p">,</span>
  <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span>
  <span class="s1">&#39;is_unbalance&#39;</span><span class="p">:</span> <span class="s1">&#39;true&#39;</span><span class="p">,</span>
  <span class="s1">&#39;boosting&#39;</span><span class="p">:</span> <span class="s1">&#39;gbdt&#39;</span><span class="p">,</span>
  <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">31</span><span class="p">,</span>
  <span class="s1">&#39;feature_fraction&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
  <span class="s1">&#39;bagging_fraction&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
  <span class="s1">&#39;bagging_freq&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
  <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="mi">0</span>
<span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">lightgbm</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span>
                      <span class="n">train_data</span><span class="p">,</span>
                      <span class="n">valid_sets</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                      <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                      <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div>


<h4 id="catboost">CatBoost</h4>
<p><a href="https://catboost.ai">Category Boosting</a> has high performances compared to other popular models, and does not require conversion of categorical values into numbers. It is said to be even faster than LighGBM, and allows model to be ran using GPU. </p>
<h2 id="voting">Voting</h2>
<p>The idea behind the <a href="https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier">VotingClassifier</a> is to combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.</p>
<p>Tree ensembles is an example of a majority voting model.</p>
<h2 id="stacking">Stacking</h2>
<p><a href="https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization">Stacked generalization</a> is a method for combining estimators to reduce their biases. More precisely, the predictions of each individual estimator are stacked together and used as input to a final estimator to compute the prediction. This final estimator is trained through cross-validation.</p>
<p>The fundamental difference between voting and stacking is how the final aggregation is done. In voting, user-specified weights are used to combine the classifiers whereas stacking performs this aggregation by using a blender/meta classifier.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../model-concepts/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Model Concepts
              </div>
            </div>
          </a>
        
        
          <a href="../model-supervised2/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Regression
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.fd16492e.min.js"></script>
      <script src="../assets/javascripts/bundle.7836ba4d.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>